\documentclass[8pt,landscape]{article}

% PACKAGES
\usepackage[letterpaper, margin=0.1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{multicol}
\usepackage{setspace}
\usepackage{sectsty}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{enumitem}

\setlist{nosep, leftmargin=*}
\lstset{
  basicstyle=\ttfamily\footnotesize,
  backgroundcolor=\color{gray!10},
  frame=single,
  breaklines=true,
  columns=fullflexible,
  showstringspaces=false,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{orange}
}
% FORMATTING
\setstretch{0.9}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}

% Reduce subsection spacing and make subsections blue
\makeatletter
\renewcommand{\subsection}{\@startsection{subsection}{2}{0pt}%
    {0.2ex}% space before subsection
    {0.2ex}% space after subsection
    {\fontsize{8}{8}\bfseries\color{blue}}} % font size, bold, blue color
\makeatother
% Custom small text wrapper
\newcommand{\smalltext}[1]{%
  {\fontsize{8}{7}\selectfont\sloppy #1\par}%
}

% DOCUMENT START
\begin{document}
\pagestyle{empty}
\begin{multicols}{3}
\subsection*{How Do We Perform Estimation?}
\begin{enumerate}\fontsize{8}{8}\selectfont
    \item Define the population of interest.
    \item Select the right sampling method according to the specific characteristics of our population of interest.
    \item Select our sample size (Power Analysis).
    \item Collect the sampled data.
    \item Measure and calculate the sample statistic.
    \item Infer the population value based on this sample statistic while accounting for sampling uncertainty.
\end{enumerate}

\subsection*{Population Proportion ${P}_E$}
\begin{lstlisting}[language=R]
listings |>
  group_by(room_type) |>
  summarise(n = n()) |>
  mutate(freq = round(n / sum(n), 3))
\end{lstlisting}
\begin{lstlisting}[language=R]
library(infer)
# Sampling WITHOUT replacement is the default
sample_1 <- rep_sample_n(listings, size = 40) 
#This gives us 100 random samples of size n = 40 from the population
samples_100 <- rep_sample_n(listings, size = 40, reps = 100) 
sampling_dist <- samples_100 |>
  group_by(replicate) |>
  summarise(
    n_E = sum(room_type == "Entire home/apt"),
    p_hat_E = sum(room_type == "Entire home/apt") / 40
  )
#Mean of sampling dist
mean_sampling_dist <- sampling_dist |>
    pull(p_hat_E)|>
    mean() |>
    round(3)
#Histogram plot of sampling_dist_plot
sampling_dist_plot <- sampling_dist |>
  ggplot(aes(x = p_hat_E)) +
  geom_histogram(binwidth = 0.025) +
  xlab("Sample Proportion Based on n = 40") +
  ggtitle("Sampling Dist of the Sample Proportions") +
  theme(text = element_text(size = 16.5)) +
  scale_x_continuous(breaks = seq(0.4, 1, 0.05)) +
  geom_vline(xintercept = 0.756, color = "red") # Mean proportion estimate as a vertical red line
  summary(df$column) #Get summary of column
\end{lstlisting}

\subsection*{Why Sampling Distributions?}
\smalltext{Sampling is usually costly in terms of human, monetary, and time resources. \\
There might be some ethical implications in a given inferential/causal study. \\
Since our sample statistic is also a random variable, it will have some variability associated when estimating a population parameter.\\
The sample distribution and the sampling distribution of the sample estimate are not the same. \\
They also do not relate to the population in the same manner.
Mean of Population = Multiple samples mean 
}
\begin{lstlisting}[language=R]
  multiple_samples_n50 <- rep_sample_n(listings, size = 50, reps = 1000) 
  multiple_samples_mean_price_n50 <- multiple_samples_n50 |>
  summarise(sample_mean = mean(price))
\end{lstlisting}
\smalltext{The distribution of one\_sample looks somewhat like the distribution of the population. \\
Sample mean is not exactly equal to the population mean. \\
The shape of the sampling distribution from multiple\_samples\_n50 is different from the shape of the population distribution and the sample distribution. \\
}
\subsection*{Sampling Distributions and their Relationship to Sample Size n}
\smalltext{As we increase the sample size n, \\
 - our sampling distribution gets narrower. \\
 - the standard error gets smaller. \\
 - each sample is more likely to have an estimate closer to the true population parameter we are trying to estimate (compared to samples with a smaller number of observations).
}
\subsection*{Quantifying the variability/uncertainty around our point estimate vary from sample to sample.Two ways to quantify}
\begin{enumerate}\fontsize{8}{8}\selectfont
 \item Via computation: We can use bootstrapping. This approach is pretty flexible since it can be applied to different statistics such as the sample mean, median, a given quantile, etc.
 \item Via a theoretical shortcut: Central Limit Theorem (CLT).
\end{enumerate}

\subsection*{Bootstrapping}
\smalltext{
A random sample taken with replacement from the original sample of the same size n. \\
Calculate the bootstrap point estimate from that bootstrap sample. \\
Do this multiple reps and calculate the point estimates for all the reps (empirical confidence interval)
}
\begin{lstlisting}[language=R]
  six_bootstrap_samples <- one_sample |>
  rep_sample_n(size = 50, replace = TRUE, reps = 6)
\end{lstlisting}
\smalltext{There is a bell shape in both sampling distributions. Moreover, we could state that the spread is graphically similar, except for some outliers on the right-hand side for the regular sampling distribution. This makes the distribution slightly right-skewed. \\
The means of these two distributions are different: the mean of the bootstrap sample means is almost exactly that of the original one\_sample mean, whereas the mean of the sampling distribution of sample means is almost exactly that of the population parameter.
}
\subsection*{Confidence Intervals}
\smalltext{No, confidence intervals are not done only on bootstrapped samples.
If you take a larger sample size $n$, your confidence interval at a specified level will narrower.
If we report a point estimate, we probably will not hit the exact value of the population parameter.
If we report a range of plausible values, we have a good shot at capturing the parameter.
95\% of the time, we would expect our population parameter’s value to lie within the confidence interval.
One way to calculate a range of plausible values for the population parameter 95 percentile.
Two samples of the same size are drawn from the same population, a 95\% confidence interval from sample A will always be wider than a 90\% confidence interval from sample B? True, but not always - it depends on the variability in the observations of the samples.
}
\begin{enumerate}\fontsize{8}{8}\selectfont
\item Our endpoints are at the 2.5th and 97.5th percentiles.
\item For the bootstrap distribution below, the values of 21 and 29.3
\end{enumerate}
\begin{lstlisting}[language=R]
  bootstrap_dist <- df |>
    specify(response = col) |>
    generate(reps = 10000, type = "bootstrap") |>
    calculate(stat = "median")
  ci <- bootstrap_dist |>
    get_confidence_interval(level = 0.90, type = "percentile")
\end{lstlisting}

\subsection*{Questions we can answer with hypothesis testing}
\smalltext{hypothesis tests are necessary for many important Data Science-related inquiries (mostly inferential or causal, and sometimes even predictive!)}
\begin{enumerate}\fontsize{8}{8}\selectfont
\item Null hypothesis ($H_o$): The status quo. It is usually a claim that there really is “no effect” or “no difference”.
\item Alternative hypothesis ($H_A$): Our hypothesis of interest. It is the claim for which we seek significant statistical evidence. 
\end{enumerate}
\subsection*{Hypotheses in A/B Testing}
\smalltext{Let us revisit the A/B testing question: will changing the design of the website lead to a change in customer engagement (measured by the CTRs)?}
\begin{enumerate}\fontsize{8}{8}\selectfont
\item Null hypothesis The population CTRs for the two versions of the website are equal
\item Alternative hypothesis The population CTRs for the two versions of the website are NOT equal.
\end{enumerate}

\subsection*{The Hypothesis Testing Framework}
\smalltext{
  Our testing procedure is developed under a null framework, i.e., the one corresponding to $H_O$\\
  Provided a strong enough statistical evidence via our random sample drawn from the population of interest, we can reject $H_O$
 in favour of $H_A$
}

\subsection*{How to assess the sample's statistical evidence?}
\smalltext{
Create a model of what we would expect under the null hypothesis, $H_O$\\
Define a test statistic that corresponds to our model of $H_O$\\
Since we are working under a null framework, we assume that ANY observed difference between both treatments will only happen due to chance. \\
Therefore, any permuted relabeling WOULD BE as similar as our real observed $\delta$. This method is called permutation (sampling WITHOUT replacement).

}
\subsection*{Six Steps of Hypothesis Testing/ A-B Testing}
\begin{enumerate}\fontsize{8}{8}\selectfont
    \item Define your null and alternative hypotheses.
    \item Compute the \textbf{observed} test statistic $\hat{\delta}$ coming from your original sample.
    \item Use the null model to generate \textbf{r random permuted} samples from the original sample and calculate their corresponding $r$ test statistics.
    \item Generate the null distribution using these $r$ test statistics.
    \item Check where your \textbf{observed} test statistic $\hat{\delta}$ falls on this distribution.
    \item If $\hat{\delta}$ is near the extremes past some threshold defined with a significance level $\alpha$ (i.e., $p$-value is less than $\alpha$), we reject the null hypothesis. Otherwise, we fail to reject the null hypothesis.
\end{enumerate}
\begin{lstlisting}[language=R]
ci_mean <- function(sample, var, level = 0.95, type = "percentile") {
  sample |>
  rep_sample_n(nrow(sample), replace = TRUE, reps = 15000) |>
  summarise(stat = mean({{ var }})) |>
  get_confidence_interval(level = level, type = type)
}
ownership_means <- ownership_data |>
  group_by(ownership) |>
  nest() |>
  mutate(
  ci = map(data, ~ ci_mean(.x, percent_score)),
  mean = map_dbl(data, ~ mean(.x$percent_score))
  ) |>
  unnest(ci)
ownership_means <- ownership_data |>
  group_by(ownership) |>
  summarise(mean = mean(percent_score, na.rm = TRUE))
public_mean <- ownership_means |> filter(ownership == "Public") |> pull(mean)
private_mean <- ownership_means |> filter(ownership == "Private") |> pull(mean)
delta_star <- public_mean - private_mean
null_distribution_ownership <- ownership_data |>
  specify(formula = percent_score ~ ownership) |>
  hypothesize(null = "independence") |>
  generate(1000, type = "permute") |>
  calculate(stat = 'diff in means', order = c('Public','Private'))
#Since alpha is 0.05 
threshold <- quantile(null_distribution_ownership$stat, c(0.025, 0.975))
#p-value 
ownership_pvalue <- null_distribution_ownership |>
  get_p_value(obs_stat = delta_star, direction = "two-sided")


\end{lstlisting}
\end{multicols}
\end{document}